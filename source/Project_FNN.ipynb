{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYJVB3fKCW7X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF-uqoSWColr",
        "outputId": "ea6ca138-8cda-466a-b7d5-1e11de430265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVjzpM5DDGLG",
        "outputId": "0dad4c84-8f53-47a2-996e-af96d7a2c23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Final Year Project/DelhiRiotstweets.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLKIBE34DR02",
        "outputId": "9b829a24-e81c-44e9-ed8c-f9c17ebfc385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "senNum = {'negative': 0, 'positive': 1, 'neutral': 2}\n",
        "takeThis = [sum(df['sentiment'] == 'positive')]*3 # take these many samples of each of the classes\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in df.index:\n",
        "  if sum(takeThis):\n",
        "    idx = senNum[df['sentiment'][i]]\n",
        "    if takeThis[idx]:\n",
        "      X += [df['tweet'][i]]\n",
        "      y += [idx]\n",
        "      takeThis[idx] -= 1\n",
        "    continue\n",
        "  break"
      ],
      "metadata": {
        "id": "u8qSnrEoDf4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the balanced data set"
      ],
      "metadata": {
        "id": "U5Og_QotHKRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df = pd.DataFrame(list(zip(X, y)), columns = ['Tweet', 'Sentiment'])"
      ],
      "metadata": {
        "id": "lNk_sZgjHJbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df.to_csv('/content/drive/MyDrive/Final Year Project/BalancedRiotsTweets.csv')"
      ],
      "metadata": {
        "id": "geOK1BK1C4A5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the balanced data set "
      ],
      "metadata": {
        "id": "NHtKU1L3DHUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df = pd.read_csv('/content/drive/MyDrive/Final Year Project/BalancedRiotsTweets.csv')"
      ],
      "metadata": {
        "id": "S2gj35m-DGuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizing the tweets"
      ],
      "metadata": {
        "id": "1jnlYLagGxPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = balanced_df['Tweet']"
      ],
      "metadata": {
        "id": "pGO9RLvjHfg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = balanced_df['Sentiment']"
      ],
      "metadata": {
        "id": "6nkhThPQgqKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = []\n",
        "\n",
        "stemmer = WordNetLemmatizer()\n",
        "\n",
        "for sen in range(0, len(X)):\n",
        "    # Remove all the special characters\n",
        "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
        "    \n",
        "    # remove all single characters\n",
        "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
        "    \n",
        "    # Remove single characters from the start\n",
        "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
        "    \n",
        "    # Substituting multiple spaces with single space\n",
        "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "        \n",
        "    # Converting to Lowercase\n",
        "    document = document.lower()\n",
        "    \n",
        "    # Lemmatization\n",
        "    document = document.split()\n",
        "\n",
        "    document = [stemmer.lemmatize(word) for word in document]\n",
        "    document = ' '.join(document)\n",
        "    documents.append(document)"
      ],
      "metadata": {
        "id": "nx69H3paGq5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
        "X = tfidfconverter.fit_transform(documents).toarray()"
      ],
      "metadata": {
        "id": "j0vPMUkIHmr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TweetDataset(Dataset):\n",
        "  def __init__(self, tweets, labels):\n",
        "    self.tweets = tweets\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    label = self.labels[idx]\n",
        "    tweet = self.tweets[idx]\n",
        "    sample = {'Tweet': tweet, 'Label': label}\n",
        "    return sample"
      ],
      "metadata": {
        "id": "lfTjAB5UFdOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing 80-20 train/test split on the data set "
      ],
      "metadata": {
        "id": "5tilvhwZEC1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X[: 35000])\n",
        "y_train = np.array(y[: 35000])"
      ],
      "metadata": {
        "id": "1zmi21HSEMUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = TweetDataset(X_train, y_train)"
      ],
      "metadata": {
        "id": "woGkh63eEhpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array(X[35000: ])\n",
        "y_test = np.array(y[35000: ])\n",
        "test_ds = TweetDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "oOyySzwbEscs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying out the custom dataloader"
      ],
      "metadata": {
        "id": "HXWKh291ES86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(train_ds, batch_size = 2, shuffle = True)\n",
        "for idx, batch in enumerate(dataloader):\n",
        "  if idx == 3:\n",
        "    break\n",
        "  print(f\"Batch #: {idx}\\n Tweets: {batch['Tweet']}\")\n",
        "  print(f\"Batch #: {idx}\\n Labels: {batch['Label']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo8rmck5ENs4",
        "outputId": "fe88ca7a-dc32-4e53-a7b9-8f6618e1a64f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch #: 0\n",
            " Tweets: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
            "Batch #: 0\n",
            " Labels: tensor([0, 0])\n",
            "Batch #: 1\n",
            " Tweets: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
            "Batch #: 1\n",
            " Labels: tensor([0, 0])\n",
            "Batch #: 2\n",
            " Tweets: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
            "Batch #: 2\n",
            " Labels: tensor([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "num_epochs = 5\n",
        "input_dim = 1500  # The value we set as 'max_features' in tfidfvectorizer "
      ],
      "metadata": {
        "id": "9rYqURv9KQc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedforwardNeuralNetModel(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super(FeedforwardNeuralNetModel, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.sigmoid(out)\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "r69xat7WKsNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FeedforwardNeuralNetModel(input_dim, hidden_dim = 750, output_dim = 3).to(device)  # output_dim is the number of classes"
      ],
      "metadata": {
        "id": "UTFJcznfjebV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "IrdcPx_NtSB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.007\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "B1fy19Tnl2U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_ds, batch_size = batch_size, shuffle = False)\n",
        "test_loader = DataLoader(test_ds, batch_size = 4, shuffle = False)"
      ],
      "metadata": {
        "id": "F2Gb-tIMmE88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expected_accuracy = 93  # Change this to max. attained accuracy (IMPORTANT)"
      ],
      "metadata": {
        "id": "zjjDG0PyvIqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Final Year Project/Saved Models/model2'"
      ],
      "metadata": {
        "id": "y8u-MAbYwDOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for batch in train_loader:\n",
        "    tweets = batch['Tweet'].view(-1, input_dim).type(torch.FloatTensor).requires_grad_()\n",
        "    labels = batch['Label'].type(torch.LongTensor)\n",
        "    tweets = tweets.to(device)\n",
        "    labels = labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(tweets)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  #if not (epoch % 5):\n",
        "  if True:\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for idx, batch in enumerate(train_loader):\n",
        "      tweets = batch['Tweet'].view(-1, input_dim).type(torch.FloatTensor)\n",
        "      labels = batch['Label'].type(torch.LongTensor)\n",
        "      tweets = tweets.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(tweets)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Epoch: {epoch}, Accuracy: {accuracy: .2f}')\n",
        "    '''\n",
        "    if accuracy > expected_accuracy:\n",
        "      expected_accuracy = accuracy \n",
        "      torch.save(model.state_dict(), path)\n",
        "    '''\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru6XR5NHqu7C",
        "outputId": "ecf705dc-b218-4cd3-97df-0c8706b45c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Accuracy:  94.23\n",
            "Epoch: 1, Accuracy:  94.32\n",
            "Epoch: 2, Accuracy:  95.07\n",
            "Epoch: 3, Accuracy:  96.73\n",
            "Epoch: 4, Accuracy:  97.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Accuracy"
      ],
      "metadata": {
        "id": "QZQO22oswUMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = total = 0\n",
        "# Checking accuracy on test set\n",
        "for idx, batch in enumerate(test_loader):\n",
        "  tweets = batch['Tweet'].view(-1, input_dim).type(torch.FloatTensor)\n",
        "  labels = batch['Label'].type(torch.LongTensor)\n",
        "  tweets = tweets.to(device)\n",
        "  labels = labels.to(device)\n",
        "  outputs = model(tweets)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  total += labels.size(0)\n",
        "  correct += (predicted == labels).sum()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Test Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxvsbh7Qv6Vl",
        "outputId": "a97881d2-6c7b-4c6a-d4c1-523a49257956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 86.09343719482422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model1 train accuracy: 85.99% &nbsp; test accuracy: 87.57%\n",
        "<br>\n",
        "model2 train accuracy: 97.51% &nbsp; test accuracy: 86.09%"
      ],
      "metadata": {
        "id": "z8Kr60nsz792"
      }
    }
  ]
}